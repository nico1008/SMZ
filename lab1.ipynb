{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2D(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
    "  def convolution(matrix):\n",
    "    if (in_channels % groups != 0) or (out_channels % groups != 0):\n",
    "     raise ValueError('in_channels and out_channels must be divisible by groups')\n",
    "\n",
    "    # Generate bias values\n",
    "    bias_values = torch.rand(out_channels) if bias else torch.zeros(out_channels)\n",
    "\n",
    "    # Padding mode exceptions\n",
    "    valid_padding_modes = ['zeros', 'reflect', 'replicate', 'circular']\n",
    "    if padding_mode not in valid_padding_modes:\n",
    "        raise ValueError(f'Invalid padding_mode. Supported modes are: {valid_padding_modes}')    \n",
    "\n",
    "    def generate_kernel(out_channels, in_channels, kernel_size, groups):\n",
    "      if isinstance(kernel_size, tuple):\n",
    "          filters = torch.rand(out_channels, in_channels // groups, kernel_size[0], kernel_size[1])\n",
    "      elif isinstance(kernel_size, int):\n",
    "          filters = torch.rand(out_channels, in_channels // groups, kernel_size, kernel_size)\n",
    "      else:\n",
    "          raise ValueError('Invalid kernel_size type. Supported types are: int or tuple of ints')\n",
    "\n",
    "      return filters\n",
    "\n",
    "      # Generate padding\n",
    "    if padding_mode == 'zeros':\n",
    "        pad = torch.nn.ZeroPad2d(padding)\n",
    "    elif padding_mode == 'reflect':\n",
    "        pad = torch.nn.ReflectionPad2d(padding)\n",
    "    elif padding_mode == 'replicate':\n",
    "        pad = torch.nn.ReplicationPad2d(2)\n",
    "    elif padding_mode == 'circular':\n",
    "        pad = torch.nn.CircularPad2d(padding)\n",
    "    else:\n",
    "        raise ValueError('Invalid padding_mode. Supported modes are: \"zeros\", \"reflect\", \"replicate\", \"circular\"')\n",
    "    matrix = pad(matrix)\n",
    "    \n",
    "  # Generate kernel\n",
    "    filters = generate_kernel(out_channels, in_channels, kernel_size, groups)\n",
    "\n",
    "    result_list = []\n",
    "    for l in range(out_channels):\n",
    "\n",
    "      feature_map = np.array([])  # Инициализация пустой карты признаков\n",
    "\n",
    "      # Цикл по ширине входной карты признаков с учетом размера фильтра, дилатации и шага\n",
    "      for i in range(0, matrix.shape[1] - ((filters.shape[2] - 1) *\n",
    "                                            dilation + 1) + 1, stride):\n",
    "\n",
    "        # Цикл по высоте входной карты признаков с учетом размера фильтра, дилатации и шага\n",
    "        for j in range(0, matrix.shape[2] - ((filters.shape[3] - 1) *\n",
    "                                              dilation + 1) + 1, stride):\n",
    "\n",
    "          # Инициализация переменной для хранения суммы сверток для текущей позиции\n",
    "          total = 0\n",
    "          for c in range(in_channels // groups):\n",
    "             # Выбор соответствующего среза входной матрицы для операции свертки\n",
    "            if groups > 1:\n",
    "              val = matrix[l * (in_channels // groups) + c][i:i + (filters.shape[2] - 1) * dilation + 1:dilation,\n",
    "                                                             j:j + (filters.shape[3] - 1) * dilation + 1:dilation]\n",
    "            else:\n",
    "              # Извлекаем подматрицу из входной матрицы matrix для одного канала (c)\n",
    "              # с использованием трехмерного среза по ширине, высоте и глубине\n",
    "              # Срез происходит вдоль каждого измерения с шагом dilation\n",
    "              # Начальные индексы для каждого измерения определяются переменными i, j\n",
    "              # и учитывают размеры фильтра и дилатацию\n",
    "              val = matrix[c]                              [i:i + (filters.shape[2] - 1) * dilation + 1:dilation,\n",
    "                                                             j:j + (filters.shape[3] - 1) * dilation + 1:dilation]\n",
    "              \n",
    "            # Подсчет суммы элементов после умножения на веса фильтра\n",
    "            local_sum = (val * filters[l][c]).sum()\n",
    "            total = total + local_sum\n",
    "            \n",
    "          #расширяем массив feature_map, добавляя новое значение, которое является суммой total и смещения для конкретного выходного канала\n",
    "          feature_map = np.append(feature_map, float(total + bias_values[l]))\n",
    "\n",
    "      # Добавление feature_map в result_list с учетом изменения формы\n",
    "      result_list.append(feature_map.reshape(\n",
    "        (matrix.shape[1] - ((filters.shape[2] - 1) * \n",
    "                            dilation + 1)) // stride + 1,  # вычитаем из размера второй оси входной матрицы размер свертки с учетом дилатации. Полученное значение представляет собой \"виртуальную\" длину, на которую мы можем сдвинуть фильтр вдоль входных каналов.\n",
    "        (matrix.shape[2] - ((filters.shape[3] - 1) * \n",
    "                            dilation + 1)) // stride + 1)) # выражение вычитает из размера третьей оси входной матрицы размер свертки с учетом дилатации вдоль ширины. Полученное значение представляет собой \"виртуальную\" длину, на которую мы можем сдвинуть фильтр вдоль ширины.\n",
    "\n",
    "    return np.array(result_list), np.array(filters), np.array(bias_values)\n",
    "\n",
    "  return convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_tensor(shape):\n",
    "    return torch.rand(shape)\n",
    "\n",
    "def compare_convolutions(custom_conv, torch_conv, input_tensor):\n",
    "    result, kernel, bias_val = custom_conv(input_tensor)\n",
    "    torch_conv.weight.data = torch.tensor(kernel)\n",
    "    torch_conv.bias.data = torch.tensor(bias_val)\n",
    "\n",
    "    custom_result = str(np.round(result, 2))\n",
    "    torch_result = str(np.round(np.array(torch_conv(input_tensor).data), 2))\n",
    "\n",
    "    assert torch_result == custom_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1():\n",
    "    tensor = create_random_tensor((10, 28, 28))\n",
    "    conv = Conv2D(               in_channels=10, out_channels=2, kernel_size=3, stride=1, padding=0, dilation=1, groups=2, bias=True, padding_mode='zeros')\n",
    "    torch_conv = torch.nn.Conv2d(in_channels=10, out_channels=2, kernel_size=3, stride=1, padding=0, dilation=1, groups=2, bias=True, padding_mode='zeros')\n",
    "    compare_convolutions(conv, torch_conv, tensor)\n",
    "\n",
    "def test_2():\n",
    "    tensor = create_random_tensor((3, 100, 100))\n",
    "    conv = Conv2D(               in_channels=3, out_channels=1, kernel_size=4, stride=2, padding=0, dilation=2, groups=1, bias=True, padding_mode='zeros')\n",
    "    torch_conv = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=4, stride=2, padding=0, dilation=2, groups=1, bias=True, padding_mode='zeros')\n",
    "    compare_convolutions(conv, torch_conv, tensor)\n",
    "\n",
    "def test_3():\n",
    "    tensor = create_random_tensor((4, 4, 4))\n",
    "    conv = Conv2D(               in_channels=4, out_channels=4, kernel_size=1, stride=1, padding=0, dilation=1, groups=4, bias=True, padding_mode='zeros')\n",
    "    torch_conv = torch.nn.Conv2d(in_channels=4, out_channels=4, kernel_size=1, stride=1, padding=0, dilation=1, groups=4, bias=True, padding_mode='zeros')\n",
    "    compare_convolutions(conv, torch_conv, tensor)\n",
    "    \n",
    "def test_4():\n",
    "    tensor = create_random_tensor((3, 128, 128))\n",
    "    conv = Conv2D(               in_channels=3, out_channels=1, kernel_size=1, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "    torch_conv = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=1, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "    compare_convolutions(conv, torch_conv, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                         [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 2.85s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipytest.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
