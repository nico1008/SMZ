{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## функция Convolution Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bias(out_channels, bias):\n",
    "    if bias:\n",
    "        return torch.rand(out_channels)\n",
    "    else:\n",
    "        return torch.zeros(out_channels)\n",
    "\n",
    "def generate_filter(in_channels, out_channels, kernel_size):\n",
    "    if type(kernel_size) == tuple:\n",
    "        return torch.rand(in_channels, out_channels, kernel_size[0], kernel_size[1])\n",
    "    elif type(kernel_size) == int:\n",
    "        return torch.rand(in_channels, out_channels, kernel_size, kernel_size)\n",
    "\n",
    "def apply_dilation(total_mult, dilation):\n",
    "    zero_tensor = torch.zeros(\n",
    "        (total_mult.shape[0] - 1) * dilation + 1,\n",
    "        (total_mult.shape[1] - 1) * dilation + 1\n",
    "    )\n",
    "\n",
    "    for a in range(0, zero_tensor.shape[0], dilation):\n",
    "        for b in range(0, zero_tensor.shape[1], dilation):\n",
    "            zero_tensor[a][b] = total_mult[a // dilation][b // dilation]\n",
    "\n",
    "    return zero_tensor\n",
    "\n",
    "def update_feature_map(feature_map, res, i, j, stride, dilation, filter):\n",
    "    updated_map = np.add(\n",
    "        feature_map[i * stride:i * stride + (filter.shape[2] - 1) * dilation + 1,\n",
    "        j * stride:j * stride + (filter.shape[3] - 1) * dilation + 1],\n",
    "        res\n",
    "    )\n",
    "    feature_map[i * stride:i * stride + (filter.shape[2] - 1) * dilation + 1,\n",
    "    j * stride:j * stride + (filter.shape[3] - 1) * dilation + 1] = updated_map\n",
    "    return feature_map\n",
    "\n",
    "def process_padding(convolution, output_padding, padding):\n",
    "    for t in range(len(convolution)):\n",
    "        if output_padding > 0:\n",
    "            padded = torch.nn.ConstantPad1d((0, output_padding, 0, output_padding), 0)\n",
    "            convolution[t] = padded(convolution[t])\n",
    "\n",
    "        convolution[t] = convolution[t][0 + padding:convolution[t].shape[0] - padding,\n",
    "                         0 + padding:convolution[t].shape[1] - padding]\n",
    "\n",
    "    return convolution\n",
    "\n",
    "def ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, dilation=1, bias=True, padding_mode='zeros'):\n",
    "    def convolution(matrix):\n",
    "        if padding_mode != 'zeros':\n",
    "            raise Exception('Only \"zeros\" padding mode is supported in ConvTranspose2d')\n",
    "\n",
    "        bias_values = generate_bias(out_channels, bias)\n",
    "        filter = generate_filter(in_channels, out_channels, kernel_size)\n",
    "\n",
    "        convolution = []\n",
    "\n",
    "        for l in range(out_channels):\n",
    "            feature_map = torch.zeros(\n",
    "                (matrix.shape[1] - 1) * stride + dilation * (kernel_size - 1) + 1,\n",
    "                (matrix.shape[2] - 1) * stride + dilation * (kernel_size - 1) + 1\n",
    "            )\n",
    "\n",
    "            for c in range(in_channels):\n",
    "                for i in range(0, matrix.shape[1]):\n",
    "                    for j in range(0, matrix.shape[2]):\n",
    "                        val = matrix[c][i][j]\n",
    "                        total_mult = val * filter[c][l]\n",
    "                        zero_tensor = apply_dilation(total_mult, dilation)\n",
    "                        feature_map = update_feature_map(feature_map, zero_tensor, i, j, stride, dilation, filter)\n",
    "\n",
    "            convolution.append(np.add(feature_map, np.full((feature_map.shape), bias_values[l])))\n",
    "\n",
    "        convolution = process_padding(convolution, output_padding, padding)\n",
    "\n",
    "        return convolution, filter, torch.tensor(bias_values)\n",
    "\n",
    "    return convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1():\n",
    "    tensor2 = torch.rand(3, 18, 18)\n",
    "    myFunction2 = ConvTranspose2d(in_channels=3, out_channels=2, kernel_size=3, stride=10, padding=0,output_padding=0, dilation=3, bias=True, padding_mode='zeros')\n",
    "    result, kernel, bias_val = myFunction2(tensor2)\n",
    "    torchFunction2 = torch.nn.ConvTranspose2d(in_channels=3, out_channels=2, kernel_size=3, stride=10, padding=0,output_padding=0, dilation=3, bias=True, padding_mode='zeros')\n",
    "    torchFunction2.weight.data = kernel\n",
    "    torchFunction2.bias.data = bias_val\n",
    "    result_array = np.array(result) if isinstance(result, list) else result.numpy()\n",
    "    assert np.allclose(result_array, torchFunction2(tensor2).data.numpy())\n",
    "\n",
    "def test_2():\n",
    "    tensor2 = torch.rand(1, 11, 11)\n",
    "    myFunction2 = ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=1, stride=1, padding=0,output_padding=0, dilation=3, bias=True, padding_mode='zeros')\n",
    "    result, kernel, bias_val = myFunction2(tensor2)\n",
    "    torchFunction2 = torch.nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=1, stride=1, padding=0,output_padding=0, dilation=3, bias=True, padding_mode='zeros')\n",
    "    torchFunction2.weight.data = kernel\n",
    "    torchFunction2.bias.data = bias_val\n",
    "    result_array = np.array(result) if isinstance(result, list) else result.numpy()\n",
    "    assert np.allclose(result_array, torchFunction2(tensor2).data.numpy())\n",
    "\n",
    "def test_3():\n",
    "    tensor2 = torch.rand(3, 10, 10)\n",
    "    myFunction2 = ConvTranspose2d(in_channels=3, out_channels=2, kernel_size=3, stride=10, padding=0,output_padding=0, dilation=3, bias=True, padding_mode='zeros')\n",
    "    result, kernel, bias_val = myFunction2(tensor2)\n",
    "    torchFunction2 = torch.nn.ConvTranspose2d(in_channels=3, out_channels=2, kernel_size=3, stride=10, padding=0,output_padding=0, dilation=3, bias=True, padding_mode='zeros')\n",
    "    torchFunction2.weight.data = kernel\n",
    "    torchFunction2.bias.data = bias_val\n",
    "    result_array = np.array(result) if isinstance(result, list) else result.numpy()\n",
    "    assert np.allclose(result_array, torchFunction2(tensor2).data.numpy())\n",
    "\n",
    "def test_4():\n",
    "    tensor2 = torch.rand(2, 12, 12)\n",
    "    myFunction2 = ConvTranspose2d(in_channels=2, out_channels=2, kernel_size=3, stride=10, padding=0,output_padding=0, dilation=3, bias=True, padding_mode='zeros')\n",
    "    result, kernel, bias_val = myFunction2(tensor2)\n",
    "    torchFunction2 = torch.nn.ConvTranspose2d(in_channels=2, out_channels=2, kernel_size=3, stride=10, padding=0,output_padding=0, dilation=3, bias=True, padding_mode='zeros')\n",
    "    torchFunction2.weight.data = kernel\n",
    "    torchFunction2.bias.data = bias_val\n",
    "    result_array = np.array(result) if isinstance(result, list) else result.numpy()\n",
    "    assert np.allclose(result_array, torchFunction2(tensor2).data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доп. Задание: реализовать алгоритм работы транспонированной свертки, через алгоритм двумерной свертки, реализованный в первой лабораторной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transpose_padding(matr, transp_stride, pad):\n",
    "    # Generate zero tensor\n",
    "    zero_tensor = np.zeros((((matr.shape[0] - 1) * transp_stride) + 1, ((matr.shape[1] - 1) * transp_stride) + 1))\n",
    "    \n",
    "    # Apply transposition with the specified stride\n",
    "    for a in range(0, zero_tensor.shape[0], transp_stride):\n",
    "        for b in range(0, zero_tensor.shape[1], transp_stride):\n",
    "            zero_tensor[a][b] = matr[a // transp_stride][b // transp_stride]\n",
    "\n",
    "    # Add padding to the obtained matrix\n",
    "    pad_matr = np.pad(zero_tensor, pad_width=pad, mode='constant')\n",
    "    \n",
    "    return pad_matr\n",
    "\n",
    "def process_output_channel(matrix, filter, bias_values, in_channels, dilation, stride, l):\n",
    "    feature_map = np.array([])\n",
    "\n",
    "    # Iterate over the height and width of the matrix considering the kernel size and dilation\n",
    "    for i in range(0, matrix.shape[1] - ((filter.shape[2] - 1) * dilation + 1) + 1, stride):\n",
    "        for j in range(0, matrix.shape[2] - ((filter.shape[3] - 1) * dilation + 1) + 1, stride):\n",
    "            total = 0\n",
    "\n",
    "            # Iterate over input channels (in_channels)\n",
    "            for c in range(in_channels):\n",
    "                val = matrix[c][i:i + (filter.shape[2] - 1) * dilation + 1:dilation,\n",
    "                      j:j + (filter.shape[3] - 1) * dilation + 1:dilation]\n",
    "\n",
    "                local_sum = (val * filter[l][c]).sum()\n",
    "                total = total + local_sum\n",
    "\n",
    "            # Add the convolution result and bias to the feature-map\n",
    "            feature_map = np.append(feature_map, float(total + bias_values[l]))\n",
    "\n",
    "    # Convert the feature-map to a matrix and return it\n",
    "    return feature_map.reshape(\n",
    "        (matrix.shape[1] - ((filter.shape[2] - 1) * dilation + 1)) // stride + 1,\n",
    "        (matrix.shape[2] - ((filter.shape[3] - 1) * dilation + 1)) // stride + 1)\n",
    "\n",
    "def select_padding_mode(padding_mode, padding):\n",
    "    if padding_mode == 'zeros':\n",
    "        return torch.nn.ZeroPad2d(padding)\n",
    "    elif padding_mode == 'reflect':\n",
    "        return torch.nn.ReflectionPad2d(padding)\n",
    "    elif padding_mode == 'replicate':\n",
    "        return torch.nn.ReplicationPad2d(padding)\n",
    "    elif padding_mode == 'circular':\n",
    "        # You can implement circular padding based on your requirements\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported padding mode: {padding_mode}\")\n",
    "\n",
    "def select_bias(bias, out_channels):\n",
    "    if bias:\n",
    "        # If bias is enabled, create random values for bias\n",
    "        return torch.rand(out_channels)\n",
    "    else:\n",
    "        # Otherwise, set bias to zeros\n",
    "        return torch.zeros(out_channels)\n",
    "\n",
    "def myTranspConv2dInverse(in_channels, out_channels, kernel_size, transp_stride=1, padding=0, dilation=1, bias=True, padding_mode='zeros'):\n",
    "    def convolution(matrix):\n",
    "        # Calculate padding to be added to the input matrix\n",
    "        pad = kernel_size - 1\n",
    "        result_matrix = []\n",
    "\n",
    "        # Apply transposition and padding to each matrix in the input\n",
    "        for matr in matrix:\n",
    "            pad_matr = apply_transpose_padding(matr, transp_stride, pad)\n",
    "            result_matrix.append(pad_matr)\n",
    "\n",
    "        # Convert the input matrix to a PyTorch tensor\n",
    "        matrix = torch.tensor(result_matrix)\n",
    "\n",
    "        # Select bias values\n",
    "        bias_values = select_bias(bias, out_channels)\n",
    "\n",
    "        # Select the padding mode based on the specified value (padding_mode)\n",
    "        pad = select_padding_mode(padding_mode, padding)\n",
    "        matrix = pad(matrix)\n",
    "\n",
    "        # Generate a random convolution kernel\n",
    "        filter = np.array(torch.rand(out_channels, in_channels, kernel_size, kernel_size))\n",
    "\n",
    "        # Transpose the kernel for ConvTranspose2d\n",
    "        filter_for_transpose = []\n",
    "\n",
    "        # External loop over the number of output channels (out_channels)\n",
    "        for j in range(out_channels):\n",
    "            # Initialize a temporary list filter_in for the current output channel\n",
    "            filter_in = []\n",
    "\n",
    "            # Internal loop over the number of input channels (in_channels)\n",
    "            for i in range(in_channels):\n",
    "                # Add the transposed filter to filter_in.\n",
    "                # np.flip() - perform \"flip\" operation reversing the order of elements along the specified axis.\n",
    "                filter_in.append(np.flip(np.array(filter[j][i])))\n",
    "\n",
    "            # Add filter_in (transposed filter for the current output channel) to filter_for_transpose\n",
    "            filter_for_transpose.append(filter_in)\n",
    "\n",
    "        # Convert the filter_for_transpose list to a torch tensor\n",
    "        filter_for_transpose = torch.tensor(filter_for_transpose)\n",
    "\n",
    "        # Reshape the tensor filter_for_transpose to the required shape considering the kernel size (kernel_size)\n",
    "        filter_for_transpose = filter_for_transpose.reshape(in_channels, out_channels, kernel_size, kernel_size)\n",
    "\n",
    "        # Initial values for stride and convolution result\n",
    "        stride = 1\n",
    "        convolution_result = []\n",
    "\n",
    "        # Iterate over output channels (out_channels)\n",
    "        for l in range(out_channels):\n",
    "            # Process each output channel using the function\n",
    "            feature_map = process_output_channel(matrix, filter, bias_values, in_channels, dilation, stride, l)\n",
    "            convolution_result.append(feature_map)\n",
    "\n",
    "        return np.array(convolution_result), torch.tensor(np.array(filter_for_transpose)), torch.tensor(np.array(bias_values))\n",
    "\n",
    "    return convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test2(test_name, in_channels, out_channels, kernel_size, transp_stride, input_shape):\n",
    "    tensor = torch.rand(*input_shape)\n",
    "    my_function = myTranspConv2dInverse(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, transp_stride=transp_stride, bias=True)\n",
    "    result, kernel, bias_val = my_function(tensor)\n",
    "    \n",
    "    torch_function = torch.nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=transp_stride, bias=True)\n",
    "    torch_function.weight.data = kernel\n",
    "    torch_function.bias.data = bias_val\n",
    "    \n",
    "    my_result = str(np.round(result, 2))\n",
    "    torch_result = str(np.round(np.array(torch_function(tensor).data), 2))\n",
    "    assert torch_result == my_result, f\"Test {test_name} failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_5():\n",
    "    run_test2(\"test_1\", in_channels=3, out_channels=1, kernel_size=3, transp_stride=2, input_shape=(3, 5, 6))\n",
    "\n",
    "def test_6():\n",
    "    run_test2(\"test_2\", in_channels=1, out_channels=2, kernel_size=4, transp_stride=3, input_shape=(1, 28, 28))\n",
    "\n",
    "def test_7():\n",
    "    run_test2(\"test_3\", in_channels=7, out_channels=1, kernel_size=3, transp_stride=1, input_shape=(7, 10, 10))\n",
    "\n",
    "def test_8():\n",
    "    run_test2(\"test_3\", in_channels=7, out_channels=1, kernel_size=3, transp_stride=5, input_shape=(7, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                                                                     [100%]\u001b[0m\n",
      "\u001b[33m======================================== warnings summary =========================================\u001b[0m\n",
      "t_df59012e712e4290bdc31bf627c46a20.py::test_1\n",
      "t_df59012e712e4290bdc31bf627c46a20.py::test_2\n",
      "t_df59012e712e4290bdc31bf627c46a20.py::test_3\n",
      "t_df59012e712e4290bdc31bf627c46a20.py::test_4\n",
      "  C:\\Users\\Никола\\AppData\\Local\\Temp\\ipykernel_15856\\3863638600.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "    return convolution, filter, torch.tensor(bias_values)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m8 passed\u001b[0m, \u001b[33m\u001b[1m4 warnings\u001b[0m\u001b[33m in 4.26s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipytest.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
